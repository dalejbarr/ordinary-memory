#+TITLE:    Speech analysis sensitivity (exp 3)
#+AUTHOR:   Dale Barr and Kieran O'Shea
#+PROPERTY: header-args:R :tangle scripts/03_sensitivity.R

- warning for people reading the R file

#+BEGIN_SRC R
  #####################################################################
  ## NOTE: this script was automatically generated from the master file
  ##       03_sensitivity.org.
  ##
  ##       Use GNU make + Makefile to generate.
  ##       It was not intended to be edited by hand.
  #####################################################################

#+END_SRC

* Load data and calculate means, etc. that we need to report
  
#+NAME: exp3_load
#+BEGIN_SRC R 
  options(warn = -1)

  # load in the exp 1 data and compute things we need for tables and text
  suppressWarnings(suppressPackageStartupMessages({
    library("parallel")
    library("lme4")
    library("tidyverse")
  }))

  simulate_newdata <- function(mod, d, deff = lme4::fixef(mod)["VP"]) {
    fx <- lme4::fixef(mod)

    ## get random effects
    rx_int_s <- sqrt(as.numeric(lme4::VarCorr(mod)[["SessionID"]]))
    rx_slp_s <- sqrt(as.numeric(lme4::VarCorr(mod)[["SessionID.1"]]))
    rx_int_i <- sqrt(as.numeric(lme4::VarCorr(mod)[["Series"]]))

    ## build table of subjects with random effects
    t1 <- d %>%
      distinct(SessionID) %>%
      mutate(rint = rnorm(length(SessionID), sd = rx_int_s),
	     rslp = rnorm(length(SessionID), sd = rx_slp_s))

    ## build table of items with random effects
    t2 <- d %>%
      distinct(Series) %>%
      mutate(rint = rnorm(length(Series), sd = rx_int_i))

    d %>%
      select(-misspec) %>%
      inner_join(t1, "SessionID") %>%
      inner_join(t2, "Series", suffix = c(".s", ".i")) %>%
      mutate(eta = fx["(Intercept)"] + rint.s + rint.i +
	       fx["SD"] * SD +
	       (deff + rslp) * VP +
	       fx["A"] * A +
	       fx["SD:VP"] * SD * VP +
	       fx["SD:A"] * SD * A +
	       fx["VP:A"] * VP * A +
	       fx["SD:VP:A"] * SD * VP * A,
	     misspec = map_int(
	       eta, ~ sample(c(1L, 0L), 1L,
			     prob = c(1 / (1 + exp(-.x)),
				      1 - (1 / (1 + exp(-.x))))))) %>%
      select(SessionID, Series, SD, VP, A, eta, misspec)
  }

  calc_propeff <- function(d) {
    ## calculate marginal effect of D (proportional scale)
    d %>%
      group_by(VP) %>%
      summarize(m = mean(misspec), .groups = "drop") %>%
      pull(m)
  }

  calc_p <- function(d) {
    ## fit the model and get the (one-tailed) p value
    suppressMessages({m <- lme4::glmer(misspec ~ SD * VP * A +
					 (1 | Series) +
					 (VP || SessionID),
				       d, family = binomial(link = "logit"),
				       control = lme4::glmerControl(optimizer = "bobyqa"))})

    tstat <- lme4::fixef(m)["VP"] / sqrt(lme4::vcov.merMod(m)["VP", "VP"])
    as.numeric(pnorm(tstat, lower.tail = FALSE))
  }

  .obj1 <- load("data_images/01_preprocess.rda")
  .obj2 <- load("data_images/02_analyze_speech.rda")

  cdat <- main_data %>%
      mutate(Addressee = if_else(PragCon, "same", "different"),
	     `Visible Partner` = if_else(PercCon, "same", "different")) %>%
      rename(`Shift Direction` = shift_dir) %>%
    select(-PragCon, -PercCon) %>%
    mutate(VP = (`Visible Partner` == "same") -
	     mean(`Visible Partner` == "same"),
	   A = (Addressee == "same") -
	     mean(Addressee == "same"),
	   SD = (`Shift Direction` == "Singleton-Contrast") -
	     mean(`Shift Direction` == "Singleton-Contrast"))

  mod_vp <- glmer(misspec ~ SD * VP * A +
		    (VP || Series) +
		    (VP || SessionID),
		  cdat, family = binomial(link = "logit"),
		  control = glmerControl(optimizer = "bobyqa"))


  ## first test whether random slope of visible partner was significant
  mod_vp2 <- glmer(misspec ~ SD * VP * A +
		     (VP || Series) +
		     (1 | SessionID),
		  cdat, family = binomial(link = "logit"),
		  control = glmerControl(optimizer = "bobyqa"))

  mod_vp3 <- glmer(misspec ~ SD * VP * A +
		     (1 | Series) +
		     (VP || SessionID),
		  cdat, family = binomial(link = "logit"),
		  control = glmerControl(optimizer = "bobyqa"))

  ## is there evidence for significant by-subject variance in the effect
  ## of congruency?
  d_rslp_est_s <- sqrt(as.numeric(VarCorr(mod_vp)[["SessionID.1"]][1, 1]))
  d_rslp_chi_s <- abs(2 * logLik(mod_vp2) - 2 * logLik(mod_vp)) %>%
    as.numeric()
  ## pchisq(d_rslp_chi_s, 1L, lower.tail = FALSE)

  ## is there evidence for significant by-item variance in the effect
  ## of congruency?
  d_rslp_est_i <- sqrt(as.numeric(VarCorr(mod_vp)[["Series.1"]][1, 1]))
  d_rslp_chi_i <- abs(2 * logLik(mod_vp3) - 2 * logLik(mod_vp)) %>%
    as.numeric()

  cl <- makeCluster(if (detectCores() > 3L) {
		      detectCores() - 2L
		    } else {
		      detectCores()})
  invisible(clusterCall(cl, function(x) {library("tidyverse")}))
  clusterExport(cl, c("simulate_newdata", "calc_propeff", "calc_p",
		      "mod_vp3", "cdat"))

  ## test raw logit effect size .1, .2, .3, .4, .5, .6
  ## with 1000 runs for each
  eff_sizes <- rep(seq(.1, .5, length.out = 6), each = 1000)

  ## run and store as a table
  message("    Running sensitivity analysis (takes a long time)...")
  sensitivity <- parSapply(cl, eff_sizes, function(deff) {
    d <- simulate_newdata(mod_vp3, cdat, deff)
    meff <- calc_propeff(d)
    pt <- calc_p(d)
    c(deff = deff, highdist = meff[1], lowdist = meff[2], p = pt)}) %>%
    t() %>%
    as_tibble()

  stopCluster(cl)

  message("    Writing data_images/03_sensitivity.rda...")
  save(list = c("d_rslp_est_s", "d_rslp_chi_s",
		"d_rslp_est_i", "d_rslp_chi_i",
		"sensitivity"),
       file = "data_images/03_sensitivity.rda")
#+END_SRC

